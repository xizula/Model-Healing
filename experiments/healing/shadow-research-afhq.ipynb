{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependecies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:46:54.729185Z",
     "iopub.status.busy": "2025-06-09T21:46:54.728976Z",
     "iopub.status.idle": "2025-06-09T21:46:59.103535Z",
     "shell.execute_reply": "2025-06-09T21:46:59.102757Z",
     "shell.execute_reply.started": "2025-06-09T21:46:54.729166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:46:59.104489Z",
     "iopub.status.busy": "2025-06-09T21:46:59.104196Z",
     "iopub.status.idle": "2025-06-09T21:46:59.110977Z",
     "shell.execute_reply": "2025-06-09T21:46:59.110145Z",
     "shell.execute_reply.started": "2025-06-09T21:46:59.104471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "project_root = Path.cwd().resolve().parents[2]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "data_root = project_root / \"data\"\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from notebook_setup import setup_notebook\n",
    "\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:46:59.113371Z",
     "iopub.status.busy": "2025-06-09T21:46:59.112815Z",
     "iopub.status.idle": "2025-06-09T21:47:00.424997Z",
     "shell.execute_reply": "2025-06-09T21:47:00.424475Z",
     "shell.execute_reply.started": "2025-06-09T21:46:59.113353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "from utils.utils import DEVICE\n",
    "\n",
    "print(f\"Device used: {DEVICE}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "from utils.utils import set_seed\n",
    "\n",
    "set_seed()\n",
    "\n",
    "from utils.utils import save_model\n",
    "\n",
    "# Prepare Dataloaders\n",
    "from methods.naive.naive_utils import init_dataloaders\n",
    "\n",
    "# Train loop\n",
    "from utils.train_test_metrics import train_model\n",
    "\n",
    "# Plot losses\n",
    "from utils.train_test_metrics import plot_training_history\n",
    "\n",
    "# Test function\n",
    "from utils.train_test_metrics import test_model\n",
    "\n",
    "# Merics\n",
    "from utils.train_test_metrics import show_metrics\n",
    "\n",
    "# Init model\n",
    "from models.effnetb0 import init_model_effnetb0, load_model_effnetb0\n",
    "\n",
    "from methods.fisher.fisher_utils import iterative_fisher_unlearn\n",
    "\n",
    "# from methods.influence.influence_utils import iterative_influence_unlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters (arbitrary chosen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.426019Z",
     "iopub.status.busy": "2025-06-09T21:47:00.425615Z",
     "iopub.status.idle": "2025-06-09T21:47:00.429823Z",
     "shell.execute_reply": "2025-06-09T21:47:00.428994Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.426000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representative & Backup Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.430928Z",
     "iopub.status.busy": "2025-06-09T21:47:00.430685Z",
     "iopub.status.idle": "2025-06-09T21:47:00.479924Z",
     "shell.execute_reply": "2025-06-09T21:47:00.479242Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.430905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def select_representative_and_backup_indices(dataset, rep_size=25000):\n",
    "    \"\"\"\n",
    "    Randomly select rep_size indices from the dataset as the representative subset,\n",
    "    and treat the remaining indices as the backup set.\n",
    "    \"\"\"\n",
    "    total_indices = list(range(len(dataset)))\n",
    "    rep_indices = random.sample(total_indices, rep_size)\n",
    "    backup_indices = list(set(total_indices) - set(rep_indices))\n",
    "    return rep_indices, backup_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearn Sample Selection (for target class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.480928Z",
     "iopub.status.busy": "2025-06-09T21:47:00.480684Z",
     "iopub.status.idle": "2025-06-09T21:47:00.491843Z",
     "shell.execute_reply": "2025-06-09T21:47:00.491302Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.480901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def select_class_samples(dataset, indices, target_class, num_samples=25):\n",
    "    \"\"\"\n",
    "    From the provided list of original indices (within the dataset),\n",
    "    randomly select num_samples that belong to the specified target_class.\n",
    "    \"\"\"\n",
    "    target_indices = [idx for idx in indices if dataset[idx][1] == target_class]\n",
    "    if len(target_indices) < num_samples:\n",
    "        raise ValueError(\n",
    "            f\"Not enough samples of class {target_class} available (found {len(target_indices)}).\"\n",
    "        )\n",
    "    return random.sample(target_indices, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.492886Z",
     "iopub.status.busy": "2025-06-09T21:47:00.492623Z",
     "iopub.status.idle": "2025-06-09T21:47:00.502427Z",
     "shell.execute_reply": "2025-06-09T21:47:00.501707Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.492864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, base_dataset, indices):\n",
    "        self.base = base_dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        orig_idx = self.indices[i]\n",
    "        img, _ = self.base[orig_idx]\n",
    "        return orig_idx, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.503464Z",
     "iopub.status.busy": "2025-06-09T21:47:00.503229Z",
     "iopub.status.idle": "2025-06-09T21:47:00.517704Z",
     "shell.execute_reply": "2025-06-09T21:47:00.517113Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.503443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def find_unique_shadow_twins_raw(\n",
    "    dataset,\n",
    "    backup_indices,\n",
    "    unlearn_indices,\n",
    "    score_type=\"l2\",\n",
    "    batch_size=256,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    For each unlearn sample (specified by its original index in the full dataset),\n",
    "    find a unique shadow twin from backup_indices based on a similarity metric computed on raw pixel vectors.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (Dataset): The full dataset, where dataset[idx][0] returns an image tensor.\n",
    "        backup_indices (list[int]): Indices for candidate backup samples.\n",
    "        unlearn_indices (list[int]): Indices for samples to be unlearned.\n",
    "        score_type (str): The metric to use: \"l2\" for Euclidean distance or \"mahalanobis\" for Mahalanobis distance.\n",
    "\n",
    "    Returns:\n",
    "        mapping (dict): A mapping from each unlearn sample original index to its unique backup index.\n",
    "        similarity_metrics (dict): A mapping from each unlearn sample original index to its computed distance.\n",
    "                                  (Lower values indicate higher similarity.)\n",
    "    \"\"\"\n",
    "\n",
    "    # Helper: load & flatten a list of indices into a single [N × D] tensor\n",
    "    def load_flat(idxs, to_device=None):\n",
    "        ds = IndexedDataset(dataset, idxs)\n",
    "        loader = DataLoader(\n",
    "            ds, batch_size=batch_size, num_workers=4, shuffle=False, pin_memory=True\n",
    "        )\n",
    "        flats = []\n",
    "        for _, img_batch in tqdm(loader, desc=\"Loading & flattening\"):\n",
    "            flat = img_batch.flatten(1)\n",
    "            flats.append(flat.to(to_device) if to_device else flat)\n",
    "        return torch.cat(flats, dim=0)\n",
    "\n",
    "    # 1) Load & flatten UNLEARN set (small M) → GPU\n",
    "    u_imgs = load_flat(unlearn_indices, to_device=device)  # [M, D]\n",
    "\n",
    "    # 2) If Mahalanobis, precompute global whitening on ALL backups\n",
    "    if score_type.lower() == \"mahalanobis\":\n",
    "        # 2a) flatten all backups on CPU\n",
    "        b_all = load_flat(backup_indices, to_device=None).double()  # [K, D] on CPU\n",
    "        mu = b_all.mean(dim=0, keepdim=True)  # [1, D]\n",
    "        Xc = b_all - mu\n",
    "        cov = (Xc.t() @ Xc) / (b_all.size(0) - 1)  # [D, D]\n",
    "        cov += 1e-5 * torch.eye(cov.size(0))  # regularize\n",
    "        inv_L = torch.linalg.cholesky(torch.inverse(cov))  # [D, D] on CPU\n",
    "\n",
    "        # Move whitening to GPU and whiten u_imgs once\n",
    "        mu_dev = mu.to(device)\n",
    "        inv_L_dev = inv_L.to(device)\n",
    "        u_imgs = (u_imgs - mu_dev) @ inv_L_dev.T  # [M, D] ← now whitened\n",
    "\n",
    "    # 3) Stream through backup chunks on GPU to compute distances\n",
    "    ds = IndexedDataset(dataset, backup_indices)\n",
    "    loader = DataLoader(\n",
    "        ds, batch_size=batch_size, num_workers=4, shuffle=False, pin_memory=True\n",
    "    )\n",
    "\n",
    "    dists_chunks = []\n",
    "    for _, b_img_batch in tqdm(loader, desc=\"Streaming BACKUP\"):\n",
    "        b_flat = b_img_batch.flatten(1).to(device)  # [B, D]\n",
    "\n",
    "        if score_type.lower() == \"l2\":\n",
    "            # Euclidean on raw pixels\n",
    "            d_chunk = torch.cdist(u_imgs, b_flat, p=2)  # [M, B]\n",
    "\n",
    "        else:\n",
    "            # Mahalanobis: whiten this chunk and compute Euclid.\n",
    "            b_w = (b_flat - mu_dev) @ inv_L_dev.T  # [B, D]\n",
    "            d_chunk = torch.cdist(u_imgs, b_w, p=2)  # [M, B]\n",
    "\n",
    "        dists_chunks.append(d_chunk)\n",
    "\n",
    "    # 4) Build full [M, K] distance matrix\n",
    "    dists = torch.cat(dists_chunks, dim=1)  # [M, K]\n",
    "\n",
    "    # 5) Greedy “first-free” matching to get 25 unique twins\n",
    "    mapping, similarity = {}, {}\n",
    "    used = torch.zeros(dists.size(1), dtype=torch.bool, device=device)\n",
    "\n",
    "    for i in range(dists.size(0)):\n",
    "        for cand in torch.argsort(dists[i]):  # lowest‐distance first\n",
    "            if not used[cand]:\n",
    "                ui = unlearn_indices[i]\n",
    "                bi = backup_indices[cand.item()]\n",
    "                mapping[ui] = bi\n",
    "                similarity[ui] = float(dists[i, cand].item())\n",
    "                used[cand] = True\n",
    "                break\n",
    "\n",
    "    return mapping, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.520255Z",
     "iopub.status.busy": "2025-06-09T21:47:00.520065Z",
     "iopub.status.idle": "2025-06-09T21:47:00.534444Z",
     "shell.execute_reply": "2025-06-09T21:47:00.533843Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.520241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_unique_shadow_twins_features(\n",
    "    model,\n",
    "    dataset,\n",
    "    backup_indices,\n",
    "    unlearn_indices,\n",
    "    score_type=\"cosine\",  # \"cosine\" or \"mahalanobis\"\n",
    "    batch_size=256,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    # 1) Unwrap & move to single GPU\n",
    "    base_model = model.module if hasattr(model, \"module\") else model\n",
    "    base_model = base_model.to(device).eval()\n",
    "\n",
    "    # 2) Hook avgpool — overwrite output every batch\n",
    "    hook_out = {}\n",
    "    hook = base_model.avgpool.register_forward_hook(\n",
    "        lambda module, inp, out: hook_out.update({\"f\": out})\n",
    "    )\n",
    "\n",
    "    # 3) Feature extractor helper\n",
    "    def extract_feats(indices):\n",
    "        ds = IndexedDataset(dataset, indices)\n",
    "        loader = DataLoader(\n",
    "            ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "        )\n",
    "        idxs_list, feats_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for idx_batch, img_batch in tqdm(loader, desc=\"Extracting features\"):\n",
    "                imgs = img_batch.to(device, non_blocking=True)\n",
    "                _ = base_model(imgs)\n",
    "                feats = hook_out[\"f\"].flatten(1)  # [B, F]\n",
    "                idxs_list.append(idx_batch.to(device))\n",
    "                feats_list.append(feats)\n",
    "        idxs = torch.cat(idxs_list, dim=0)\n",
    "        feats = torch.cat(feats_list, dim=0)\n",
    "        return idxs, feats\n",
    "\n",
    "    # 4) Extract unlearn & backup features\n",
    "    u_idx, u_feat = extract_feats(unlearn_indices)  # [M], [M, F]\n",
    "    b_idx, b_feat = extract_feats(backup_indices)  # [K], [K, F]\n",
    "    hook.remove()\n",
    "\n",
    "    # 5) Compute similarity/distance matrix\n",
    "    if score_type == \"cosine\":\n",
    "        u_n = F.normalize(u_feat, dim=1)  # [M, F]\n",
    "        b_n = F.normalize(b_feat, dim=1)  # [K, F]\n",
    "        matrix = u_n @ b_n.t()  # higher = more similar\n",
    "        higher_is_better = True\n",
    "\n",
    "    elif score_type == \"mahalanobis\":\n",
    "        # Cast to double for stable covariance\n",
    "        b_d = b_feat.double()\n",
    "        mean_d = b_d.mean(0, keepdim=True)  # [1, F]\n",
    "        Xc = b_d - mean_d\n",
    "        cov = (Xc.t() @ Xc) / (b_d.size(0) - 1)\n",
    "        cov += 1e-5 * torch.eye(cov.size(0), device=device, dtype=torch.double)\n",
    "        inv_L_d = torch.linalg.cholesky(torch.inverse(cov))\n",
    "        inv_L = inv_L_d.to(torch.float32)\n",
    "\n",
    "        # Whiten features\n",
    "        mean_f = mean_d.to(torch.float32)\n",
    "        u_w = (u_feat - mean_f) @ inv_L.t()  # [M, F]\n",
    "        b_w = (b_feat - mean_f) @ inv_L.t()  # [K, F]\n",
    "        matrix = torch.cdist(u_w, b_w, p=2)  # lower = more similar\n",
    "        higher_is_better = False\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"score_type must be 'cosine' or 'mahalanobis'\")\n",
    "\n",
    "    # 6) Greedy “first-free” unique matching\n",
    "    M, K = matrix.shape\n",
    "    used = torch.zeros(K, dtype=torch.bool, device=device)\n",
    "    mapping, similarity = {}, {}\n",
    "    for i in range(M):\n",
    "        row = matrix[i]\n",
    "        order = torch.argsort(-row) if higher_is_better else torch.argsort(row)\n",
    "        for c in order:\n",
    "            idx_c = c.item()\n",
    "            if not used[idx_c]:\n",
    "                ui = u_idx[i].item()\n",
    "                bi = b_idx[idx_c].item()\n",
    "                mapping[ui] = bi\n",
    "                similarity[ui] = float(row[idx_c].item())\n",
    "                used[idx_c] = True\n",
    "                break\n",
    "    torch.set_grad_enabled(True)\n",
    "    return mapping, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple base training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:00.535895Z",
     "iopub.status.busy": "2025-06-09T21:47:00.535176Z",
     "iopub.status.idle": "2025-06-09T21:47:01.161197Z",
     "shell.execute_reply": "2025-06-09T21:47:01.160578Z",
     "shell.execute_reply.started": "2025-06-09T21:47:00.535878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, model_name, criterion, optimizer, transform = init_model_effnetb0(\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "\n",
    "model_name = \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:01.162214Z",
     "iopub.status.busy": "2025-06-09T21:47:01.162021Z",
     "iopub.status.idle": "2025-06-09T21:47:01.165710Z",
     "shell.execute_reply": "2025-06-09T21:47:01.164979Z",
     "shell.execute_reply.started": "2025-06-09T21:47:01.162199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:01.166551Z",
     "iopub.status.busy": "2025-06-09T21:47:01.166382Z",
     "iopub.status.idle": "2025-06-09T21:47:01.175996Z",
     "shell.execute_reply": "2025-06-09T21:47:01.175428Z",
     "shell.execute_reply.started": "2025-06-09T21:47:01.166538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_root = Path(\"/kaggle/input/animal-faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:01.176867Z",
     "iopub.status.busy": "2025-06-09T21:47:01.176659Z",
     "iopub.status.idle": "2025-06-09T21:47:01.184649Z",
     "shell.execute_reply": "2025-06-09T21:47:01.184063Z",
     "shell.execute_reply.started": "2025-06-09T21:47:01.176845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# raw_transform = transforms.ToTensor()\n",
    "# afhq_raw = datasets.ImageFolder(root=data_root/'afhq/train', transform=raw_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:01.185568Z",
     "iopub.status.busy": "2025-06-09T21:47:01.185350Z",
     "iopub.status.idle": "2025-06-09T21:47:24.429704Z",
     "shell.execute_reply": "2025-06-09T21:47:24.428940Z",
     "shell.execute_reply.started": "2025-06-09T21:47:01.185546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_full = datasets.ImageFolder(\n",
    "    root=data_root / \"afhq/train\", transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=data_root / \"afhq/val\", transform=transform)\n",
    "\n",
    "\n",
    "data_split_path = \"afhq_data_splits.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Representative & Backup Splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.430806Z",
     "iopub.status.busy": "2025-06-09T21:47:24.430528Z",
     "iopub.status.idle": "2025-06-09T21:47:24.439624Z",
     "shell.execute_reply": "2025-06-09T21:47:24.439010Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.430784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rep_indices, backup_indices = select_representative_and_backup_indices(\n",
    "    train_dataset_full, rep_size=10000\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Representative subset size: {len(rep_indices)}; Backup subset size: {len(backup_indices)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create representative subset based on the selected indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.440366Z",
     "iopub.status.busy": "2025-06-09T21:47:24.440198Z",
     "iopub.status.idle": "2025-06-09T21:47:24.451066Z",
     "shell.execute_reply": "2025-06-09T21:47:24.450496Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.440354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rep_subset = Subset(train_dataset_full, rep_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init dataloders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.451939Z",
     "iopub.status.busy": "2025-06-09T21:47:24.451683Z",
     "iopub.status.idle": "2025-06-09T21:47:24.472041Z",
     "shell.execute_reply": "2025-06-09T21:47:24.471399Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.451919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader, classes = init_dataloaders(\n",
    "    datasets=(rep_subset, test_dataset), val_ratio=0.2, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.473003Z",
     "iopub.status.busy": "2025-06-09T21:47:24.472786Z",
     "iopub.status.idle": "2025-06-09T21:47:24.476162Z",
     "shell.execute_reply": "2025-06-09T21:47:24.475501Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.472985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.perf_counter()\n",
    "# train_model(model, model_name, train_loader, valid_loader, criterion, optimizer, num_epochs=EPOCHS)\n",
    "# end_time = time.perf_counter()  # End timer\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# print(f\"Execution time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.477357Z",
     "iopub.status.busy": "2025-06-09T21:47:24.476884Z",
     "iopub.status.idle": "2025-06-09T21:47:24.485310Z",
     "shell.execute_reply": "2025-06-09T21:47:24.484751Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.477335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# history_path = f'{model_name}_history.json'\n",
    "# plot_training_history(history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:24.486160Z",
     "iopub.status.busy": "2025-06-09T21:47:24.485990Z",
     "iopub.status.idle": "2025-06-09T21:47:45.641795Z",
     "shell.execute_reply": "2025-06-09T21:47:45.640962Z",
     "shell.execute_reply.started": "2025-06-09T21:47:24.486147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_path = f\"{model_name}_model.pth\"\n",
    "model_path = f\"/kaggle/input/ul_effnetb0/pytorch/default/2/base_model.pth\"\n",
    "test_model(model, model_name, model_path, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:45.642814Z",
     "iopub.status.busy": "2025-06-09T21:47:45.642579Z",
     "iopub.status.idle": "2025-06-09T21:47:45.865492Z",
     "shell.execute_reply": "2025-06-09T21:47:45.864773Z",
     "shell.execute_reply.started": "2025-06-09T21:47:45.642798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions_path = f\"{model_name}_predictions.json\"\n",
    "# classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "show_metrics(predictions_path, classes, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick samples to unlearn & their shadow twins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:45.866690Z",
     "iopub.status.busy": "2025-06-09T21:47:45.866399Z",
     "iopub.status.idle": "2025-06-09T21:47:45.870349Z",
     "shell.execute_reply": "2025-06-09T21:47:45.869704Z",
     "shell.execute_reply.started": "2025-06-09T21:47:45.866666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TARGET_CLASS = 2  # wildlife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:45.871239Z",
     "iopub.status.busy": "2025-06-09T21:47:45.871050Z",
     "iopub.status.idle": "2025-06-09T21:47:45.881011Z",
     "shell.execute_reply": "2025-06-09T21:47:45.880350Z",
     "shell.execute_reply.started": "2025-06-09T21:47:45.871225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes = train_dataset_full.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:47:45.882031Z",
     "iopub.status.busy": "2025-06-09T21:47:45.881780Z",
     "iopub.status.idle": "2025-06-09T21:48:37.290179Z",
     "shell.execute_reply": "2025-06-09T21:48:37.289523Z",
     "shell.execute_reply.started": "2025-06-09T21:47:45.882008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filtered_backup_indices = [\n",
    "    idx for idx in backup_indices if train_dataset_full[idx][1] == TARGET_CLASS\n",
    "]\n",
    "print(\n",
    "    f\"Filtered number of candidates of class {classes[TARGET_CLASS]}: {len(filtered_backup_indices)} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the full dataset with rep_indices to select unlearn samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:48:37.291691Z",
     "iopub.status.busy": "2025-06-09T21:48:37.291001Z",
     "iopub.status.idle": "2025-06-09T21:50:33.652157Z",
     "shell.execute_reply": "2025-06-09T21:50:33.651314Z",
     "shell.execute_reply.started": "2025-06-09T21:48:37.291666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unlearn_original_indices = select_class_samples(\n",
    "    train_dataset_full, rep_indices, TARGET_CLASS, num_samples=25\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Selected unlearn sample original indices (from full dataset): {unlearn_original_indices}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert these original indices to indices relative to the representative subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:50:33.653472Z",
     "iopub.status.busy": "2025-06-09T21:50:33.653160Z",
     "iopub.status.idle": "2025-06-09T21:50:33.659717Z",
     "shell.execute_reply": "2025-06-09T21:50:33.658998Z",
     "shell.execute_reply.started": "2025-06-09T21:50:33.653446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unlearn_relative_indices = [rep_indices.index(u) for u in unlearn_original_indices]\n",
    "print(\n",
    "    f\"Unlearn sample indices relative to representative subset: {unlearn_relative_indices}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Shadow Twin Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:50:33.664587Z",
     "iopub.status.busy": "2025-06-09T21:50:33.664361Z",
     "iopub.status.idle": "2025-06-09T21:50:33.670503Z",
     "shell.execute_reply": "2025-06-09T21:50:33.669827Z",
     "shell.execute_reply.started": "2025-06-09T21:50:33.664572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "def save_shadow_mapping(mapping, similarity, json_path, csv_path):\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(mapping, f, indent=4)\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unlearn_idx\", \"backup_idx\", \"score\"])\n",
    "        for un, back in mapping.items():\n",
    "            writer.writerow([un, back, similarity[un]])\n",
    "    print(f\"Saved JSON → {json_path} and CSV → {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:50:33.671472Z",
     "iopub.status.busy": "2025-06-09T21:50:33.671212Z",
     "iopub.status.idle": "2025-06-09T21:50:39.697919Z",
     "shell.execute_reply": "2025-06-09T21:50:39.697129Z",
     "shell.execute_reply.started": "2025-06-09T21:50:33.671457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "twin_mappings_list = []\n",
    "\n",
    "# RAW L2\n",
    "start_time = time.perf_counter()\n",
    "raw_l2_mapping, raw_l2_similarity = find_unique_shadow_twins_raw(\n",
    "    train_dataset_full,\n",
    "    filtered_backup_indices,\n",
    "    unlearn_original_indices,\n",
    "    score_type=\"l2\",\n",
    "    batch_size=32,\n",
    ")\n",
    "end_time = time.perf_counter()  # End timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.6f} seconds\")\n",
    "save_shadow_mapping(\n",
    "    raw_l2_mapping, raw_l2_similarity, \"raw_l2_mapping.json\", \"raw_l2_similarity.csv\"\n",
    ")\n",
    "twin_mappings_list.append((\"raw_l2\", raw_l2_mapping, raw_l2_similarity))\n",
    "\n",
    "# # RAW MAHALANOBIS\n",
    "# start_time = time.perf_counter()\n",
    "# raw_mahalanobis_mapping, raw_mahalanobis_similarity = find_unique_shadow_twins_raw(\n",
    "#     train_dataset_full, filtered_backup_indices, unlearn_original_indices, score_type=\"mahalanobis\", batch_size=8\n",
    "# )\n",
    "# end_time = time.perf_counter()  # End timer\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"Execution time: {elapsed_time:.6f} seconds\")\n",
    "# save_shadow_mapping(\n",
    "#     raw_mahalanobis_mapping, raw_mahalanobis_similarity,\n",
    "#     \"raw_mahalanobis_mapping.json\", \"raw_mahalanobis_similarity.csv\"\n",
    "# )\n",
    "# twin_mappings_list.append((\"raw_mahalanobis\", raw_mahalanobis_mapping, raw_mahalanobis_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:50:39.699141Z",
     "iopub.status.busy": "2025-06-09T21:50:39.698911Z",
     "iopub.status.idle": "2025-06-09T21:50:52.832803Z",
     "shell.execute_reply": "2025-06-09T21:50:52.831901Z",
     "shell.execute_reply.started": "2025-06-09T21:50:39.699119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FEATURE COSINE\n",
    "start_time = time.perf_counter()\n",
    "features_cosine_mapping, features_cosine_similarity = find_unique_shadow_twins_features(\n",
    "    model,\n",
    "    train_dataset_full,\n",
    "    filtered_backup_indices,\n",
    "    unlearn_original_indices,\n",
    "    score_type=\"cosine\",\n",
    "    batch_size=128,\n",
    ")\n",
    "end_time = time.perf_counter()  # End timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.6f} seconds\")\n",
    "save_shadow_mapping(\n",
    "    features_cosine_mapping,\n",
    "    features_cosine_similarity,\n",
    "    \"feat_cosine_mapping.json\",\n",
    "    \"feat_cosine_similarity.csv\",\n",
    ")\n",
    "twin_mappings_list.append(\n",
    "    (\"features_cosine\", features_cosine_mapping, features_cosine_similarity)\n",
    ")\n",
    "\n",
    "# FEATURE MAHALANOBIS\n",
    "start_time = time.perf_counter()\n",
    "features_mahalanobis_mapping, features_mahalanobis_similarity = (\n",
    "    find_unique_shadow_twins_features(\n",
    "        model,\n",
    "        train_dataset_full,\n",
    "        filtered_backup_indices,\n",
    "        unlearn_original_indices,\n",
    "        score_type=\"mahalanobis\",\n",
    "        batch_size=128,\n",
    "    )\n",
    ")\n",
    "end_time = time.perf_counter()  # End timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.6f} seconds\")\n",
    "save_shadow_mapping(\n",
    "    features_mahalanobis_mapping,\n",
    "    features_mahalanobis_similarity,\n",
    "    \"feat_mahalanobis_mapping.json\",\n",
    "    \"feat_mahalanobis_similarity.csv\",\n",
    ")\n",
    "twin_mappings_list.append(\n",
    "    (\n",
    "        \"features_mahalanobis\",\n",
    "        features_mahalanobis_mapping,\n",
    "        features_mahalanobis_similarity,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T21:52:24.255614Z",
     "iopub.status.busy": "2025-06-09T21:52:24.254838Z",
     "iopub.status.idle": "2025-06-09T21:52:46.035434Z",
     "shell.execute_reply": "2025-06-09T21:52:46.034324Z",
     "shell.execute_reply.started": "2025-06-09T21:52:24.255587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "output_dir = \"twin_mappings_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for method_name, mapping, _ in twin_mappings_list:\n",
    "    pairs_to_show = list(mapping.items())[:15]\n",
    "    rows = 5\n",
    "    pairs_per_row = 3\n",
    "    cols = pairs_per_row * 2  # two columns per pair (Original + Replacement)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 10))\n",
    "    fig.suptitle(method_name, fontsize=16)\n",
    "    axes = axes.reshape(rows, cols)\n",
    "\n",
    "    for i, (a_idx, b_idx) in enumerate(pairs_to_show):\n",
    "        row = i // pairs_per_row\n",
    "        col_offset = (i % pairs_per_row) * 2\n",
    "\n",
    "        # Plot A\n",
    "        img_path_a = train_dataset_full.samples[a_idx][0]\n",
    "        img_a = Image.open(img_path_a)\n",
    "        ax = axes[row, col_offset]\n",
    "        ax.imshow(img_a)\n",
    "        ax.set_title(f\"Original: {a_idx}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Plot B\n",
    "        img_path_b = train_dataset_full.samples[b_idx][0]\n",
    "        img_b = Image.open(img_path_b)\n",
    "        ax = axes[row, col_offset + 1]\n",
    "        ax.imshow(img_b)\n",
    "        ax.set_title(f\"Replacement: {b_idx}\", fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    # Save figure to file\n",
    "    filename = f\"{method_name.replace(' ', '_')}.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure for {method_name} to {filepath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.394409Z",
     "iopub.status.idle": "2025-06-09T21:50:55.394987Z",
     "shell.execute_reply": "2025-06-09T21:50:55.394866Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.394852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold naive retraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.395769Z",
     "iopub.status.idle": "2025-06-09T21:50:55.396022Z",
     "shell.execute_reply": "2025-06-09T21:50:55.395890Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.395880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gold_model, gold_model_name, criterion, optimizer, transform = init_model_effnetb0(\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "\n",
    "gold_model_name = \"gold\"\n",
    "\n",
    "\n",
    "# gold_model = nn.DataParallel(gold_model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get clean gold subset w/o samples to delete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.397200Z",
     "iopub.status.idle": "2025-06-09T21:50:55.397614Z",
     "shell.execute_reply": "2025-06-09T21:50:55.397460Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.397444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gold_rep_indices = sorted(list(set(rep_indices) - set(unlearn_original_indices)))\n",
    "print(f\"Clean representative indices count: {len(gold_rep_indices)}\")\n",
    "gold_subset = Subset(train_dataset_full, gold_rep_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.398912Z",
     "iopub.status.idle": "2025-06-09T21:50:55.399199Z",
     "shell.execute_reply": "2025-06-09T21:50:55.399048Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.399035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gold_train_loader, gold_valid_loader, gold_test_loader, classes = init_dataloaders(\n",
    "    datasets=(gold_subset, test_dataset), val_ratio=0.2, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.400883Z",
     "iopub.status.idle": "2025-06-09T21:50:55.401171Z",
     "shell.execute_reply": "2025-06-09T21:50:55.401019Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.401006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.perf_counter()\n",
    "# train_model(gold_model, gold_model_name, gold_train_loader, gold_valid_loader, criterion, optimizer, num_epochs=EPOCHS)\n",
    "# end_time = time.perf_counter()  # End timer\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# print(f\"Execution time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.401995Z",
     "iopub.status.idle": "2025-06-09T21:50:55.402296Z",
     "shell.execute_reply": "2025-06-09T21:50:55.402127Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.402111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# history_path = f'{gold_model_name}_history.json'\n",
    "# plot_training_history(history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.403611Z",
     "iopub.status.idle": "2025-06-09T21:50:55.403872Z",
     "shell.execute_reply": "2025-06-09T21:50:55.403745Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.403733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# gold_model_path = f\"{gold_model_name}_model.pth\"\n",
    "gold_model_path = f\"/kaggle/input/ul_effnetb0/pytorch/default/2/gold_model.pth\"\n",
    "test_model(gold_model, gold_model_name, gold_model_path, gold_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.405568Z",
     "iopub.status.idle": "2025-06-09T21:50:55.405855Z",
     "shell.execute_reply": "2025-06-09T21:50:55.405716Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.405700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions_path = f\"{gold_model_name}_predictions.json\"\n",
    "# classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "show_metrics(predictions_path, classes, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlearning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.406997Z",
     "iopub.status.idle": "2025-06-09T21:50:55.407297Z",
     "shell.execute_reply": "2025-06-09T21:50:55.407136Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.407123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_file = f\"{model_name}_model.pth\"\n",
    "model_file = f\"/kaggle/input/ul_effnetb0/pytorch/default/2/base_model.pth\"\n",
    "original_model, original_model_name, criterion, _optimizer, transform = (\n",
    "    load_model_effnetb0(model_pth_path=model_file)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning via fisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.408294Z",
     "iopub.status.idle": "2025-06-09T21:50:55.408561Z",
     "shell.execute_reply": "2025-06-09T21:50:55.408457Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.408439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from utils.utils import DEVICE\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "\n",
    "def compute_gradient_on_subset(model, criterion, dataset_subset, batch_size):\n",
    "    \"\"\"\n",
    "    Compute the average gradient Δ_rem = ∇L(θ, D') over the given dataset_subset.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    grad_dict = {}\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, targets in tqdm(dataloader, desc=\"Computing gradients\"):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        current_batch = inputs.size(0)\n",
    "        total_samples += current_batch\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                if name not in grad_dict:\n",
    "                    grad_dict[name] = param.grad.detach().clone() * current_batch\n",
    "                else:\n",
    "                    grad_dict[name] += param.grad.detach() * current_batch\n",
    "\n",
    "    # Average gradients over the entire subset\n",
    "    for name in grad_dict:\n",
    "        grad_dict[name] /= total_samples\n",
    "\n",
    "    ## DIAGNOSTIC: Print total number of samples used for averaging\n",
    "    print(f\"Computed gradients on {total_samples} samples.\")\n",
    "\n",
    "    return grad_dict\n",
    "\n",
    "\n",
    "def compute_fisher_on_subset(model, criterion, dataset_subset, batch_size):\n",
    "    \"\"\"\n",
    "    Compute a diagonal approximation of the Fisher Information Matrix F over the given dataset_subset.\n",
    "    It averages the squared gradients.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset_subset, batch_size=batch_size, shuffle=False)\n",
    "    fisher_diag = {}\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, targets in tqdm(dataloader, desc=\"Computing Fisher\"):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        current_batch = inputs.size(0)\n",
    "        total_samples += current_batch\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                if name not in fisher_diag:\n",
    "                    fisher_diag[name] = (param.grad.detach() ** 2) * current_batch\n",
    "                else:\n",
    "                    fisher_diag[name] += (param.grad.detach() ** 2) * current_batch\n",
    "\n",
    "    for name in fisher_diag:\n",
    "        fisher_diag[name] /= total_samples\n",
    "\n",
    "        ## DIAGNOSTIC: Print Fisher diagonal statistics to verify damping requirements\n",
    "        print(\n",
    "            f\"Fisher diag for {name}: min = {fisher_diag[name].min().item():.2e}, \"\n",
    "            f\"mean = {fisher_diag[name].mean().item():.2e}, max = {fisher_diag[name].max().item():.2e}\"\n",
    "        )\n",
    "\n",
    "    return fisher_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.409472Z",
     "iopub.status.idle": "2025-06-09T21:50:55.409751Z",
     "shell.execute_reply": "2025-06-09T21:50:55.409617Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.409605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def iterative_fisher_unlearn_simplified_golatkar(\n",
    "    model,\n",
    "    criterion,\n",
    "    full_dataset,\n",
    "    removal_indices,\n",
    "    sigma_lambda_term,\n",
    "    deletion_batch_size,  # How many indices to process per iteration\n",
    "    compute_batch_size,  # Batch size for computing Fisher\n",
    "    eps=1e-5,\n",
    "):\n",
    "\n",
    "    full_size = len(full_dataset)\n",
    "    current_indices = set(range(full_size))\n",
    "\n",
    "    removal_list = list(removal_indices)\n",
    "    num_batches = math.ceil(len(removal_list) / deletion_batch_size)\n",
    "    partitioned_removals = [\n",
    "        removal_list[i * deletion_batch_size : (i + 1) * deletion_batch_size]\n",
    "        for i in range(num_batches)\n",
    "    ]\n",
    "    print(f\"Applying simplified Golatkar Fisher (Iterative Noise Injection)...\")\n",
    "    print(\n",
    "        f\"Total deletion samples: {len(removal_list)}; partitioned into {num_batches} mini-batches (each up to {deletion_batch_size} samples).\"\n",
    "    )\n",
    "    print(f\"Noise scale term (λσ_h): {sigma_lambda_term}\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    for i, batch in enumerate(\n",
    "        tqdm(partitioned_removals, desc=\"Iterative Fisher Noise Injection\")\n",
    "    ):\n",
    "        current_indices -= set(batch)\n",
    "        updated_indices = sorted(list(current_indices))\n",
    "        dataset_remaining = Subset(full_dataset, updated_indices)\n",
    "        print(\n",
    "            f\"\\nIteration {i+1}/{num_batches}: Remaining dataset size = {len(dataset_remaining)}\"\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        fisher_diag = compute_fisher_on_subset(\n",
    "            model, criterion, dataset_remaining, compute_batch_size\n",
    "        )\n",
    "\n",
    "        model.train()\n",
    "        with torch.no_grad():\n",
    "            total_noise_norm_iter = 0.0\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad and name in fisher_diag:\n",
    "\n",
    "                    # Calculate F^(-1/4) with damping\n",
    "                    inv_fisher_quarter = (fisher_diag[name].to(DEVICE) + eps).pow(-0.25)\n",
    "\n",
    "                    # Generate Gaussian noise n ~ N(0, I)\n",
    "                    noise = torch.randn_like(param.data)\n",
    "\n",
    "                    # Calculate the noise term: (λσ_h) * F^(-1/4) *\n",
    "                    scaled_noise = sigma_lambda_term * inv_fisher_quarter * noise\n",
    "                    noise_norm = scaled_noise.norm(2).item()\n",
    "                    total_noise_norm_iter += noise_norm**2\n",
    "\n",
    "                    param.data.add_(scaled_noise)\n",
    "\n",
    "        print(\n",
    "            f\"Iteration {i+1}: Total added noise norm (sqrt sum sq) = {total_noise_norm_iter**0.5:.4e}\"\n",
    "        )\n",
    "        print(f\"Iteration {i+1}/{num_batches} noise injection completed.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.411067Z",
     "iopub.status.idle": "2025-06-09T21:50:55.411316Z",
     "shell.execute_reply": "2025-06-09T21:50:55.411194Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.411185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE_BATCH_SIZE = 64\n",
    "# MINI_BATCH_SIZE = 25\n",
    "\n",
    "# SIGMA = 1e-3\n",
    "\n",
    "# EPS = 1e-6\n",
    "# MAX_NORM = 10\n",
    "\n",
    "# import copy\n",
    "# model_to_unlearn_name = 'fisher'\n",
    "# model_to_unlearn = copy.deepcopy(original_model)\n",
    "\n",
    "# # import torch.nn as nn\n",
    "# # model_to_unlearn = nn.DataParallel(model_to_unlearn, device_ids=[0, 1])\n",
    "\n",
    "# import time\n",
    "# start_time = time.perf_counter()\n",
    "\n",
    "# unlearned_model = iterative_fisher_unlearn_simplified_golatkar(\n",
    "#         model_to_unlearn,\n",
    "#         criterion,\n",
    "#         rep_subset,  # unlearning is applied on the representative (reduced) training set\n",
    "#         unlearn_relative_indices,\n",
    "#         SIGMA,\n",
    "#         deletion_batch_size=MINI_BATCH_SIZE,\n",
    "#         compute_batch_size=COMPUTE_BATCH_SIZE,\n",
    "#         eps=EPS,\n",
    "#     )\n",
    "\n",
    "# end_time = time.perf_counter()  # End timer\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# print(f\"Execution time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning via Influence x Lissa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.412733Z",
     "iopub.status.idle": "2025-06-09T21:50:55.413087Z",
     "shell.execute_reply": "2025-06-09T21:50:55.412926Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.412912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm, trange\n",
    "from torch.amp import GradScaler, autocast\n",
    "import math\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "\n",
    "def compute_gradient_on_subset(model, criterion, dataset_subset, batch_size):\n",
    "    \"\"\"\n",
    "    Compute the average gradient Δ = (1/|D_u|) Σ_{(x,y) in D_u} ∇_θ L(θ, (x,y))\n",
    "    over the dataset_subset.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    grad_dict = {\n",
    "        name: torch.zeros_like(param, device=DEVICE)\n",
    "        for name, param in model.named_parameters()\n",
    "        if param.requires_grad\n",
    "    }\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, targets in tqdm(dataloader, desc=\"Computing gradients\"):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        current_batch = inputs.size(0)\n",
    "        total_samples += current_batch\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                grad_dict[name] += param.grad.detach().clone() * current_batch\n",
    "\n",
    "    # Average over total samples\n",
    "    for name in grad_dict:\n",
    "        grad_dict[name] /= total_samples\n",
    "\n",
    "    # Flatten all gradients into one vector\n",
    "    grad_vector = torch.cat(\n",
    "        [grad_dict[name].view(-1) for name in sorted(grad_dict.keys())]\n",
    "    )\n",
    "    return grad_vector\n",
    "\n",
    "\n",
    "def lissa_inverse_hvp(\n",
    "    model, criterion, data_loader, v, damping=1e-4, scale=100, recursion_depth=20\n",
    "):\n",
    "    convergence_threshold = 1e-4\n",
    "    ihvp_estimate = v.clone().to(DEVICE)\n",
    "    ihvp_prev = torch.zeros_like(ihvp_estimate)\n",
    "    data_iter = iter(data_loader)\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to store metrics\n",
    "    norms_history = []\n",
    "    delta_norms_history = []\n",
    "    relative_change_history = []\n",
    "\n",
    "    for step in trange(recursion_depth, desc=\"LiSSA iterations\", leave=False):\n",
    "        if step > 0:\n",
    "            ihvp_prev = ihvp_estimate.clone()\n",
    "        try:\n",
    "\n",
    "            inputs, targets = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(data_loader)\n",
    "            inputs, targets = next(data_iter)\n",
    "\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "        # Flatten gradients\n",
    "        grad_vector = torch.cat(\n",
    "            [\n",
    "                (\n",
    "                    g.contiguous().view(-1)\n",
    "                    if g is not None\n",
    "                    else torch.zeros(p.numel(), device=DEVICE)\n",
    "                )\n",
    "                for p, g in zip(model.parameters(), grads)\n",
    "            ]\n",
    "        )\n",
    "        if torch.isnan(grad_vector).any() or torch.isinf(grad_vector).any():\n",
    "            return torch.zeros_like(v)\n",
    "\n",
    "        grad_vector = grad_vector.contiguous()\n",
    "        ihvp_estimate = ihvp_estimate.contiguous()\n",
    "        hv = torch.autograd.grad(\n",
    "            torch.dot(grad_vector, ihvp_estimate.detach()),\n",
    "            model.parameters(),\n",
    "            retain_graph=False,\n",
    "        )\n",
    "        # Flatten HVP\n",
    "        hv_vector = torch.cat(\n",
    "            [\n",
    "                (\n",
    "                    h.contiguous().view(-1)\n",
    "                    if h is not None\n",
    "                    else torch.zeros(p.numel(), device=DEVICE)\n",
    "                )\n",
    "                for p, h in zip(model.parameters(), hv)\n",
    "            ]\n",
    "        )\n",
    "        if torch.isnan(hv_vector).any() or torch.isinf(hv_vector).any():\n",
    "            return torch.zeros_like(v)\n",
    "\n",
    "        # --- Update the estimate ---\n",
    "        ihvp_estimate = v + (1 - damping) * ihvp_estimate - hv_vector / scale\n",
    "        if torch.isnan(ihvp_estimate).any() or torch.isinf(ihvp_estimate).any():\n",
    "            return torch.zeros_like(v)\n",
    "\n",
    "        # --- Calculate and Store Metrics ---\n",
    "        current_norm = torch.norm(ihvp_estimate).item()\n",
    "        delta_norm = torch.norm(ihvp_estimate - ihvp_prev).item() if step > 0 else 0.0\n",
    "        prev_norm = torch.norm(ihvp_prev).item() if step > 0 else 0.0\n",
    "        relative_change = (\n",
    "            delta_norm / (prev_norm + 1e-9) if prev_norm > 1e-9 else delta_norm\n",
    "        )\n",
    "\n",
    "        norms_history.append(current_norm)\n",
    "        if step > 0:\n",
    "            delta_norms_history.append(delta_norm)\n",
    "            relative_change_history.append(relative_change)\n",
    "\n",
    "    # --- Plotting Section ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(recursion_depth), norms_history)\n",
    "    plt.title(\"Estimate Norm vs. Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Norm\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, recursion_depth), delta_norms_history)\n",
    "    plt.title(\"Absolute Change Norm vs. Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Norm of Change\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(1, recursion_depth), relative_change_history)\n",
    "    plt.title(\"Relative Change vs. Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Relative Change\")\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    final_norm = norms_history[-1] if norms_history else 0.0\n",
    "    print(f\"Final Estimate Norm: {final_norm:.4e}\")\n",
    "    if math.isnan(final_norm) or math.isinf(final_norm):\n",
    "        print(f\"🚨 ERROR: Final LiSSA estimate norm is NaN/Inf!\")\n",
    "        return torch.zeros_like(v)\n",
    "    else:\n",
    "        print(\"✅ [Debug] LiSSA estimation stable.\")\n",
    "        return ihvp_estimate / scale\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Function: Iterative Influence Unlearning\n",
    "# -----------------------------\n",
    "def iterative_influence_unlearn(\n",
    "    model,\n",
    "    criterion,\n",
    "    full_dataset,\n",
    "    removal_indices,\n",
    "    deletion_batch_size,\n",
    "    compute_batch_size,\n",
    "    eps,\n",
    "    max_norm,\n",
    "    scale=100,\n",
    "    lissa_depth=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Implements iterative Influence Unlearning:\n",
    "      For each mini-batch of deletion samples, compute the average gradient\n",
    "      Δ_u, solve v ≈ H⁻¹ Δ_u using Conjugate Gradient on the remaining data,\n",
    "      and update the model as: θ ← θ + v.\n",
    "\n",
    "    Mathematical Equations:\n",
    "      Δ_u = (1/|D_u^i|) Σ_{(x,y) in D_u^i} ∇_θ L(θ, (x,y))\n",
    "      v ≈ H⁻¹ Δ_u,  where H = ∇²_θ L(θ, D \\ D_u^i)\n",
    "      θ ← θ + v\n",
    "    \"\"\"\n",
    "    full_size = len(full_dataset)\n",
    "    current_indices = set(range(full_size))\n",
    "\n",
    "    # Partition removal_indices into mini-batches\n",
    "    removal_list = list(removal_indices)\n",
    "    num_batches = math.ceil(len(removal_list) / deletion_batch_size)\n",
    "    partitioned_removals = [\n",
    "        removal_list[i * deletion_batch_size : (i + 1) * deletion_batch_size]\n",
    "        for i in range(num_batches)\n",
    "    ]\n",
    "    print(\n",
    "        f\"Total deletion samples: {len(removal_list)}; partitioned into {num_batches} mini-batches (each up to {deletion_batch_size} samples).\"\n",
    "    )\n",
    "\n",
    "    for i, batch in enumerate(tqdm(partitioned_removals, desc=\"Influence Unlearning\")):\n",
    "        # Update remaining indices: D_current ← D \\ D_u^i\n",
    "        current_indices -= set(batch)\n",
    "        updated_indices = sorted(list(current_indices))\n",
    "        dataset_remaining = Subset(full_dataset, updated_indices)\n",
    "        print(\n",
    "            f\"Iteration {i+1}/{num_batches}: Remaining dataset size = {len(dataset_remaining)}\"\n",
    "        )\n",
    "\n",
    "        # Compute average gradient Δ_u for the deletion mini-batch\n",
    "        deleted_subset = Subset(full_dataset, batch)\n",
    "        delta = compute_gradient_on_subset(\n",
    "            model, criterion, deleted_subset, compute_batch_size\n",
    "        )\n",
    "\n",
    "        if torch.isnan(delta).any() or torch.isinf(delta).any():\n",
    "            print(\"🚨 [Debug] Gradient delta contains NaN/Inf!\")\n",
    "        else:\n",
    "            print(\"✅ [Debug] Gradient delta stable.\")\n",
    "\n",
    "        # Create a DataLoader for remaining data to approximate Hessian\n",
    "        remaining_loader = DataLoader(\n",
    "            dataset_remaining, batch_size=compute_batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        influence_update = lissa_inverse_hvp(\n",
    "            model,\n",
    "            criterion,\n",
    "            remaining_loader,\n",
    "            delta,\n",
    "            damping=eps,\n",
    "            scale=scale,\n",
    "            recursion_depth=lissa_depth,\n",
    "        )\n",
    "        # Optionally clip the update to avoid overly large changes\n",
    "        update_norm = influence_update.norm(2).item()\n",
    "        if update_norm > max_norm or math.isnan(update_norm) or math.isinf(update_norm):\n",
    "            print(\n",
    "                f\"WARNING: Clipping influence update from {update_norm:.2f} to {max_norm}\"\n",
    "            )\n",
    "            influence_update = influence_update * (max_norm / update_norm)\n",
    "        print(\n",
    "            f\"Iteration {i+1}: Influence update norm = {influence_update.norm(2).item():.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update model parameters: θ ← θ + v\n",
    "        pointer = 0\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    numel = param.numel()\n",
    "                    update_segment = influence_update[\n",
    "                        pointer : pointer + numel\n",
    "                    ].view_as(param)\n",
    "                    param.data = param.data + update_segment\n",
    "                    pointer += numel\n",
    "        print(f\"Iteration {i+1}/{num_batches} update completed.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.414531Z",
     "iopub.status.idle": "2025-06-09T21:50:55.414818Z",
     "shell.execute_reply": "2025-06-09T21:50:55.414669Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.414657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "COMPUTE_BATCH_SIZE = 2\n",
    "MINI_BATCH_SIZE = 25\n",
    "\n",
    "EPS = 1e-6\n",
    "MAX_NORM = 5  # 1, 5, 10\n",
    "LISSA_DEPTH = 100\n",
    "SCALE = 100\n",
    "\n",
    "import copy\n",
    "\n",
    "model_to_unlearn_name = \"influence\"\n",
    "model_to_unlearn = copy.deepcopy(original_model)\n",
    "\n",
    "\n",
    "# import torch.nn as nn\n",
    "# model_to_unlearn = nn.DataParallel(model_to_unlearn, device_ids=[0, 1])\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "\n",
    "unlearned_model = iterative_influence_unlearn(\n",
    "    model_to_unlearn,\n",
    "    criterion,\n",
    "    rep_subset,\n",
    "    unlearn_relative_indices,\n",
    "    MINI_BATCH_SIZE,\n",
    "    COMPUTE_BATCH_SIZE,\n",
    "    EPS,\n",
    "    MAX_NORM,\n",
    "    SCALE,\n",
    "    LISSA_DEPTH,\n",
    ")\n",
    "\n",
    "end_time = time.perf_counter()  # End timer\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.415880Z",
     "iopub.status.idle": "2025-06-09T21:50:55.416142Z",
     "shell.execute_reply": "2025-06-09T21:50:55.416032Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.416019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_model(unlearned_model, f\"{model_to_unlearn_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test unlearned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.417884Z",
     "iopub.status.idle": "2025-06-09T21:50:55.418176Z",
     "shell.execute_reply": "2025-06-09T21:50:55.418038Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.418023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, *_ = init_model_effnetb0()\n",
    "# model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "model_path = f\"{model_to_unlearn_name}_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.419121Z",
     "iopub.status.idle": "2025-06-09T21:50:55.419420Z",
     "shell.execute_reply": "2025-06-09T21:50:55.419253Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.419240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_model(model, model_to_unlearn_name, model_path, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.420738Z",
     "iopub.status.idle": "2025-06-09T21:50:55.421055Z",
     "shell.execute_reply": "2025-06-09T21:50:55.420903Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.420890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions_path = f\"{model_to_unlearn_name}_predictions.json\"\n",
    "# classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "show_metrics(predictions_path, classes, model_to_unlearn_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning on Shadow Twins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.422499Z",
     "iopub.status.idle": "2025-06-09T21:50:55.422728Z",
     "shell.execute_reply": "2025-06-09T21:50:55.422615Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.422606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# gold_train_subset = gold_train_loader.dataset\n",
    "\n",
    "# fine_tune_results = {}\n",
    "# for method_name, twin_mapping, similarity_metrics in twin_mappings_list:\n",
    "#     print(f\"\\n=== Fine-tuning using replacement method: {method_name} ===\")\n",
    "\n",
    "#     twin_indices = list(twin_mapping.values())\n",
    "#     twin_subset = Subset(train_dataset_full, twin_indices)\n",
    "#     combined_train_dataset = ConcatDataset([gold_train_subset, twin_subset])\n",
    "#     fine_tune_loader = DataLoader(\n",
    "#         combined_train_dataset,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4,\n",
    "#         pin_memory=True\n",
    "#     )\n",
    "\n",
    "#     ft_model_name = f\"fine_tuned_{model_to_unlearn_name}_on_{method_name}\"\n",
    "#     model_ft = copy.deepcopy(unlearned_model)\n",
    "\n",
    "#     LR_finetune = 1e-3\n",
    "#     # optimizer_ft = optim.AdamW(model_ft.parameters(), lr=LR_finetune, weight_decay=1e-4)\n",
    "#     optimizer_ft = optim.Adam(model_ft.parameters(), lr=LR_finetune, weight_decay=0)\n",
    "\n",
    "#     start_time = time.perf_counter()\n",
    "#     train_model(\n",
    "#         model_ft,\n",
    "#         ft_model_name,\n",
    "#         fine_tune_loader,\n",
    "#         gold_valid_loader,\n",
    "#         criterion,\n",
    "#         optimizer_ft,\n",
    "#         num_epochs=1,\n",
    "#     )\n",
    "#     end_time = time.perf_counter()\n",
    "#     training_time = end_time - start_time\n",
    "#     print(f\"Training time for {ft_model_name}: {training_time:.6f} seconds\")\n",
    "\n",
    "#     # # --- Plot Loss History ---\n",
    "#     # history_path = f'{ft_model_name}_history.json'\n",
    "#     # plot_training_history(history_path)\n",
    "\n",
    "#     # --- Evaluate Fine-Tuned Model ---\n",
    "#     model, *_ = init_model_resnet50()\n",
    "#     model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "#     test_model(model, ft_model_name, f\"{ft_model_name}_model.pth\", gold_test_loader)\n",
    "\n",
    "#     predictions_path = f'{ft_model_name}_predictions.json'\n",
    "#     show_metrics(predictions_path, classes, ft_model_name)\n",
    "\n",
    "# print(f\"\\n=== Fine-tuning using remaining set ===\")\n",
    "# ft_model_name = f\"fine_tuned_{model_to_unlearn_name}_on_remaining\"\n",
    "# model_ft = copy.deepcopy(unlearned_model)\n",
    "\n",
    "# LR_finetune = 1e-3\n",
    "# optimizer_ft = optim.Adam(model_ft.parameters(), lr=LR_finetune, weight_decay=0)\n",
    "# scheduler_ft = StepLR(optimizer_ft, step_size=2, gamma=0.5)\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# train_model(\n",
    "#     model_ft,\n",
    "#     ft_model_name,\n",
    "#     gold_train_loader,\n",
    "#     gold_valid_loader,\n",
    "#     criterion,\n",
    "#     optimizer_ft,\n",
    "#     num_epochs=1,\n",
    "# )\n",
    "# end_time = time.perf_counter()\n",
    "# training_time = end_time - start_time\n",
    "# print(f\"Training time for {ft_model_name}: {training_time:.6f} seconds\")\n",
    "\n",
    "# # # --- Plot Loss History ---\n",
    "# # history_path = f'{ft_model_name}_history.json'\n",
    "# # plot_training_history(history_path)\n",
    "\n",
    "# # --- Evaluate Fine-Tuned Model ---\n",
    "# model, *_ = init_model_resnet50()\n",
    "# model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "# test_model(model, ft_model_name, f\"{ft_model_name}_model.pth\", gold_test_loader)\n",
    "\n",
    "# predictions_path = f'{ft_model_name}_predictions.json'\n",
    "# show_metrics(predictions_path, classes, ft_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.423641Z",
     "iopub.status.idle": "2025-06-09T21:50:55.423920Z",
     "shell.execute_reply": "2025-06-09T21:50:55.423772Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.423759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils.utils import DEVICE\n",
    "\n",
    "\n",
    "def test_model(model, model_name, model_path, test_loader):\n",
    "    \"\"\"\n",
    "    Loads model state, evaluates on the test loader, saves predictions,\n",
    "    and returns the test accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model instance (architecture should match the state dict).\n",
    "        model_name (str): A name for saving predictions and logging.\n",
    "        model_path (str or Path): Path to the saved model state dictionary (.pth file).\n",
    "        test_loader (DataLoader): DataLoader for the test set.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated accuracy score on the test set.\n",
    "    \"\"\"\n",
    "    print(f\"Loading and testing model: {model_name} from {model_path}\")\n",
    "    try:\n",
    "        # Load state dict into the provided model object\n",
    "        model.load_state_dict(\n",
    "            torch.load(model_path, weights_only=True, map_location=DEVICE)\n",
    "        )\n",
    "        # model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "        # model.to(DEVICE)\n",
    "        print(\"Model state loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model state dict from {model_path}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.inference_mode():  # Use inference_mode for efficiency\n",
    "        for inputs, labels in tqdm(test_loader, desc=f\"Evaluating {model_name}\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Ensure lists are flat if model outputs batches > 1 consistently\n",
    "    predictions = np.array(predictions).flatten()\n",
    "    true_labels = np.array(true_labels).flatten()\n",
    "\n",
    "    # --- Calculate Accuracy ---\n",
    "    if len(true_labels) > 0:\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        print(f\"Test Accuracy for {model_name}: {accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"Warning: Test loader was empty. Accuracy is 0.\")\n",
    "        accuracy = 0.0\n",
    "\n",
    "    # --- Save Predictions ---\n",
    "    results = {\n",
    "        \"predictions\": predictions.tolist(),\n",
    "        \"true_labels\": true_labels.tolist(),\n",
    "    }\n",
    "    pred_file = f\"{model_name}_predictions.json\"\n",
    "    try:\n",
    "        with open(pred_file, \"w\") as f:\n",
    "            json.dump(results, f)\n",
    "        print(f\"Predictions and labels saved to {pred_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving predictions to {pred_file}: {e}\")\n",
    "\n",
    "    # --- Return Accuracy ---\n",
    "    return float(accuracy)\n",
    "\n",
    "\n",
    "RUN_DIR = Path(\"./unlearning_runs\")\n",
    "RUN_DIR.mkdir(exist_ok=True)\n",
    "NUM_RUNS = 5\n",
    "gold_standard_accuracy = 0.9940\n",
    "print(f\"Using Gold Standard Accuracy: {gold_standard_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.424871Z",
     "iopub.status.idle": "2025-06-09T21:50:55.425157Z",
     "shell.execute_reply": "2025-06-09T21:50:55.425042Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.425029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_file = f\"{model_name}_model.pth\"\n",
    "model_file = f\"/kaggle/input/ul_effnetb0/pytorch/default/2/base_model.pth\"\n",
    "original_model, original_model_name, criterion, _optimizer, transform = (\n",
    "    load_model_effnetb0(model_pth_path=model_file)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.426039Z",
     "iopub.status.idle": "2025-06-09T21:50:55.426257Z",
     "shell.execute_reply": "2025-06-09T21:50:55.426165Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.426156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "fisher_accuracies = []\n",
    "fisher_model_paths = []\n",
    "fisher_times = []\n",
    "influence_accuracies = []\n",
    "influence_model_paths = []\n",
    "influence_times = []\n",
    "\n",
    "# --- Fisher Runs ---\n",
    "print(f\"\\n--- Running Fisher Unlearning ({NUM_RUNS} runs) ---\")\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"fisher_run_{i+1}\"\n",
    "    print(f\"  Fisher Run {i+1}/{NUM_RUNS} ({run_name})\")\n",
    "\n",
    "    # Load fresh model instance and state dict for each run\n",
    "    model_to_unlearn, *_ = init_model_effnetb0()\n",
    "    model_to_unlearn = copy.deepcopy(original_model)\n",
    "    # model_to_unlearn = nn.DataParallel(model_to_unlearn, device_ids=[0, 1])\n",
    "    # model_to_unlearn.to(DEVICE)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    # Perform unlearning\n",
    "    unlearned_model_fisher = iterative_fisher_unlearn_simplified_golatkar(\n",
    "        model=model_to_unlearn,\n",
    "        criterion=criterion,\n",
    "        full_dataset=rep_subset,\n",
    "        removal_indices=unlearn_relative_indices,\n",
    "        sigma_lambda_term=1e-3,\n",
    "        deletion_batch_size=25,\n",
    "        compute_batch_size=64,\n",
    "        eps=1e-6,\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    fisher_times.append(duration)\n",
    "    print(f\"  Fisher Run {i+1} Time: {duration:.2f} seconds\")\n",
    "    model_path = RUN_DIR / f\"{run_name}.pth\"\n",
    "    save_model(unlearned_model_fisher, model_path)\n",
    "\n",
    "    # Test the unlearned model\n",
    "    eval_model, *_ = init_model_effnetb0()\n",
    "    # eval_model = nn.DataParallel(eval_model, device_ids=[0, 1])\n",
    "    accuracy = test_model(eval_model, run_name, model_path, gold_test_loader)\n",
    "    fisher_accuracies.append(accuracy)\n",
    "    fisher_model_paths.append(model_path)\n",
    "    print(f\"  Fisher Run {i+1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model_to_unlearn, unlearned_model_fisher, eval_model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.427479Z",
     "iopub.status.idle": "2025-06-09T21:50:55.427765Z",
     "shell.execute_reply": "2025-06-09T21:50:55.427649Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.427641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Influence Runs ---\n",
    "print(f\"\\n--- Running Influence Unlearning ({NUM_RUNS} runs) ---\")\n",
    "for i in range(NUM_RUNS):\n",
    "    run_name = f\"influence_run_{i+1}\"\n",
    "    print(f\"  Influence Run {i+1}/{NUM_RUNS} ({run_name})\")\n",
    "\n",
    "    # Load fresh model instance and state dict\n",
    "    model_to_unlearn, *_ = init_model_effnetb0()\n",
    "    model_to_unlearn = copy.deepcopy(original_model)\n",
    "    # model_to_unlearn = nn.DataParallel(model_to_unlearn, device_ids=[0, 1])\n",
    "    # model_to_unlearn.to(DEVICE)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Perform unlearning\n",
    "    unlearned_model_influence = iterative_influence_unlearn(\n",
    "        model=model_to_unlearn,\n",
    "        criterion=criterion,\n",
    "        full_dataset=rep_subset,\n",
    "        removal_indices=unlearn_relative_indices,\n",
    "        deletion_batch_size=25,\n",
    "        compute_batch_size=2,\n",
    "        eps=1e-6,\n",
    "        max_norm=5,\n",
    "        scale=100,\n",
    "        lissa_depth=100,\n",
    "    )\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    influence_times.append(duration)\n",
    "\n",
    "    print(f\"  Fisher Run {i+1} Time: {duration:.2f} seconds\")\n",
    "    model_path = RUN_DIR / f\"{run_name}.pth\"\n",
    "    save_model(unlearned_model_influence, model_path)\n",
    "\n",
    "    # Test\n",
    "    eval_model, *_ = init_model_effnetb0()\n",
    "    # eval_model = nn.DataParallel(eval_model, device_ids=[0, 1])\n",
    "    accuracy = test_model(eval_model, run_name, model_path, gold_test_loader)\n",
    "    influence_accuracies.append(accuracy)\n",
    "    influence_model_paths.append(model_path)\n",
    "    print(f\"  Influence Run {i+1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model_to_unlearn, unlearned_model_influence, eval_model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.428598Z",
     "iopub.status.idle": "2025-06-09T21:50:55.428896Z",
     "shell.execute_reply": "2025-06-09T21:50:55.428768Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.428746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Phase 2: Analyze Unlearning Variability & Select Representative Models\n",
    "# =============================================================================\n",
    "\n",
    "fisher_accuracies = np.array(fisher_accuracies)\n",
    "influence_accuracies = np.array(influence_accuracies)\n",
    "fisher_times = np.array(fisher_times)\n",
    "influence_times = np.array(influence_times)\n",
    "\n",
    "fisher_mean_acc = np.mean(fisher_accuracies)\n",
    "fisher_std_acc = np.std(fisher_accuracies)\n",
    "fisher_var_acc = np.var(fisher_accuracies)\n",
    "fisher_mean_time = np.mean(fisher_times)\n",
    "\n",
    "influence_mean_acc = np.mean(influence_accuracies)\n",
    "influence_std_acc = np.std(influence_accuracies)\n",
    "influence_var_acc = np.var(influence_accuracies)\n",
    "influence_mean_time = np.mean(influence_times)\n",
    "\n",
    "print(\"\\n--- Unlearning Method Stats ---\")\n",
    "print(\n",
    "    f\"Fisher   | Mean Acc: {fisher_mean_acc:.4f}, StdDev Acc: {fisher_std_acc:.4f}, Var Acc: {fisher_var_acc:.4f} | Mean Time: {fisher_mean_time:.2f}s\"\n",
    ")\n",
    "print(\n",
    "    f\"Influence| Mean Acc: {influence_mean_acc:.4f}, StdDev Acc: {influence_std_acc:.4f}, Var Acc: {influence_var_acc:.4f} | Mean Time: {influence_mean_time:.2f}s\"\n",
    ")\n",
    "\n",
    "fisher_median_idx = np.argmin(np.abs(fisher_accuracies - fisher_mean_acc))\n",
    "influence_median_idx = np.argmin(np.abs(influence_accuracies - influence_mean_acc))\n",
    "\n",
    "fisher_rep_model_path = fisher_model_paths[fisher_median_idx]\n",
    "influence_rep_model_path = influence_model_paths[influence_median_idx]\n",
    "\n",
    "fisher_rep_acc = fisher_accuracies[fisher_median_idx]\n",
    "influence_rep_acc = influence_accuracies[influence_median_idx]\n",
    "\n",
    "print(\n",
    "    f\"\\nSelected Representative Fisher Model: {fisher_rep_model_path.name} (Acc: {fisher_rep_acc:.4f})\"\n",
    ")\n",
    "print(\n",
    "    f\"Selected Representative Influence Model: {influence_rep_model_path.name} (Acc: {influence_rep_acc:.4f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.430052Z",
     "iopub.status.idle": "2025-06-09T21:50:55.430414Z",
     "shell.execute_reply": "2025-06-09T21:50:55.430230Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.430216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define Epoch settings for healing\n",
    "HEAL_BATCH_SIZE = BATCH_SIZE\n",
    "HEAL_EPOCHS_SHORT = 1\n",
    "HEAL_EPOCHS_LONG = 3\n",
    "HEAL_LR = 0.001\n",
    "epoch_settings_to_run = [HEAL_EPOCHS_SHORT, HEAL_EPOCHS_LONG]\n",
    "\n",
    "# Results dictionary to store final accuracies\n",
    "results = {\"fisher_start\": {}, \"influence_start\": {}}\n",
    "\n",
    "# Define the starting models\n",
    "start_points = {\n",
    "    \"fisher_start\": fisher_rep_model_path,\n",
    "    \"influence_start\": influence_rep_model_path,\n",
    "}\n",
    "\n",
    "# --- Define the 5 Healing Data Loaders/Configurations ---\n",
    "healing_data_configs = []\n",
    "gold_train_subset = gold_train_loader.dataset\n",
    "# Configs 1-4: FT-RemainPlusTwins\n",
    "if \"twin_mappings_list\" in locals() and twin_mappings_list:\n",
    "    print(\"--- Defining Remain+Twins Healing Loaders ---\")\n",
    "    for twin_method_name, twin_mapping, _ in twin_mappings_list:\n",
    "        print(f\"  Processing twin method: {twin_method_name}\")\n",
    "        try:\n",
    "            if not isinstance(twin_mapping, dict) or not twin_mapping:\n",
    "                print(f\"    Skipping {twin_method_name}: invalid mapping.\")\n",
    "                continue\n",
    "            twin_indices = list(twin_mapping.values())\n",
    "            if twin_indices:\n",
    "                twin_subset = Subset(train_dataset_full, twin_indices)\n",
    "                if not isinstance(gold_train_subset, torch.utils.data.Dataset):\n",
    "                    print(\"    Error: gold_train_subset is not a Dataset object.\")\n",
    "                    continue\n",
    "                combined_train_dataset = ConcatDataset([gold_train_subset, twin_subset])\n",
    "                heal_loader = DataLoader(\n",
    "                    combined_train_dataset,\n",
    "                    batch_size=HEAL_BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "                healing_data_configs.append(\n",
    "                    {\n",
    "                        \"name\": f\"RemainPlusTwins-{twin_method_name}\",\n",
    "                        \"loader\": heal_loader,\n",
    "                    }\n",
    "                )\n",
    "                print(f\"    Loader created for {twin_method_name}.\")\n",
    "            else:\n",
    "                print(f\"    Skipping {twin_method_name}: No twin indices.\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error creating loader for {twin_method_name}: {e}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: twin_mappings_list not found or empty. Cannot create twin-based healing loaders.\"\n",
    "    )\n",
    "\n",
    "# Config 5: FT-RemainOnly\n",
    "print(\"--- Defining RemainOnly Healing Loader ---\")\n",
    "healing_data_configs.append({\"name\": \"RemainOnly\", \"loader\": gold_train_loader})\n",
    "print(f\"Defined {len(healing_data_configs)} healing data configurations.\")\n",
    "\n",
    "# --- Iterate through starting models, healing datasets, and epoch settings ---\n",
    "for start_point_name, start_model_path in start_points.items():\n",
    "    print(\n",
    "        f\"\\n\\n{'='*20} Processing Start Point: {start_point_name} ({start_model_path.name}) {'='*20}\"\n",
    "    )\n",
    "\n",
    "    # Load the representative model state dict ONCE for this starting point\n",
    "    start_model, *_ = load_model_effnetb0(start_model_path)\n",
    "    initial_accuracy = (\n",
    "        fisher_rep_acc if start_point_name == \"fisher_start\" else influence_rep_acc\n",
    "    )\n",
    "    print(f\"--- Initial Accuracy for {start_point_name}: {initial_accuracy:.4f} ---\")\n",
    "\n",
    "    # Initialize nested dictionary for this start point\n",
    "    results[start_point_name] = {config[\"name\"]: {} for config in healing_data_configs}\n",
    "\n",
    "    # Iterate through the 5 healing data configurations\n",
    "    for config in healing_data_configs:\n",
    "        healing_config_name = config[\"name\"]\n",
    "        healing_loader = config[\"loader\"]\n",
    "        print(f\"\\n  --- Applying Healing using Data: {healing_config_name} ---\")\n",
    "\n",
    "        # Iterate through the epoch settings (1 and 5 epochs)\n",
    "        for num_epochs in epoch_settings_to_run:\n",
    "            print(f\"    --- Healing for {num_epochs} epoch(s) ---\")\n",
    "            try:\n",
    "                # Load fresh model instance and the STARTING state dict EVERY time\n",
    "                model_to_heal, *_ = init_model_effnetb0()\n",
    "                model_to_heal = copy.deepcopy(start_model)\n",
    "                # model_to_heal = nn.DataParallel(model_to_heal, device_ids=[0, 1])\n",
    "                model_to_heal.to(DEVICE)\n",
    "\n",
    "                # Define optimizer\n",
    "                current_lr = HEAL_LR\n",
    "                optimizer_heal = optim.Adam(\n",
    "                    model_to_heal.parameters(), lr=current_lr, weight_decay=0\n",
    "                )\n",
    "\n",
    "                # Define healed model name including epoch count\n",
    "                healed_model_name = f\"healed_{start_point_name}_using_{healing_config_name}_{num_epochs}ep\"\n",
    "\n",
    "                # Run Healing (Fine-tuning)\n",
    "                start_heal_time = time.perf_counter()\n",
    "                train_model(\n",
    "                    model=model_to_heal,\n",
    "                    model_name=healed_model_name,\n",
    "                    train_loader=healing_loader,\n",
    "                    val_loader=gold_valid_loader,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer_heal,\n",
    "                    num_epochs=num_epochs,\n",
    "                )\n",
    "                end_heal_time = time.perf_counter()\n",
    "                print(f\"      Healing time: {end_heal_time - start_heal_time:.2f}s\")\n",
    "\n",
    "                # Save the healed model\n",
    "                healed_model_path = RUN_DIR / f\"{healed_model_name}.pth\"\n",
    "                save_model(model_to_heal, healed_model_path)\n",
    "\n",
    "                # Test the healed model\n",
    "                eval_model, *_ = init_model_effnetb0()\n",
    "                # eval_model = nn.DataParallel(eval_model, device_ids=[0, 1])\n",
    "                accuracy = test_model(\n",
    "                    eval_model, healed_model_name, healed_model_path, gold_test_loader\n",
    "                )\n",
    "                results[start_point_name][healing_config_name][num_epochs] = accuracy\n",
    "                print(f\"      Healed Accuracy ({num_epochs}ep): {accuracy:.4f}\")\n",
    "\n",
    "                # Cleanup\n",
    "                del model_to_heal, optimizer_heal, eval_model\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"      ERROR during healing ({healing_config_name}, {num_epochs}ep): {e}\"\n",
    "                )\n",
    "                if \"model_to_heal\" in locals():\n",
    "                    del model_to_heal\n",
    "                if \"optimizer_heal\" in locals():\n",
    "                    del optimizer_heal\n",
    "                if \"eval_model\" in locals():\n",
    "                    del eval_model\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-09T21:50:55.431502Z",
     "iopub.status.idle": "2025-06-09T21:50:55.431812Z",
     "shell.execute_reply": "2025-06-09T21:50:55.431651Z",
     "shell.execute_reply.started": "2025-06-09T21:50:55.431641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n--- FINAL RESULTS SUMMARY ---\")\n",
    "print(f\"Gold Standard Accuracy: {gold_standard_accuracy:.4f}\")\n",
    "\n",
    "# Define the epoch counts we analyzed\n",
    "epoch_settings_analyzed = [HEAL_EPOCHS_SHORT, HEAL_EPOCHS_LONG]\n",
    "\n",
    "for start_point_name, start_acc in [\n",
    "    (\"fisher_start\", fisher_rep_acc),\n",
    "    (\"influence_start\", influence_rep_acc),\n",
    "]:\n",
    "    print(f\"\\n\\n{'='*10} Healing Summary starting from: {start_point_name} {'='*10}\")\n",
    "    print(f\"  Initial Accuracy: {start_acc:.4f}\")\n",
    "\n",
    "    healing_results_for_start = results.get(start_point_name, {})\n",
    "    if not healing_results_for_start:\n",
    "        print(\"  No healing results found for this starting point.\")\n",
    "        continue\n",
    "\n",
    "    # Analyze results separately for each epoch setting\n",
    "    for num_epochs in epoch_settings_analyzed:\n",
    "        print(f\"\\n  --- Analysis for {num_epochs}-Epoch Healing ---\")\n",
    "\n",
    "        epoch_specific_accs = {}\n",
    "        # Extract accuracies only for the current number of epochs\n",
    "        for config_name, epoch_results in healing_results_for_start.items():\n",
    "            if num_epochs in epoch_results:\n",
    "                # Store accuracy with the config name as the key\n",
    "                epoch_specific_accs[config_name] = epoch_results[num_epochs]\n",
    "\n",
    "        if not epoch_specific_accs:\n",
    "            print(f\"    No results found for {num_epochs}-epoch healing.\")\n",
    "            continue\n",
    "\n",
    "        # Find best method/accuracy for this epoch count\n",
    "        best_method_this_epoch = max(epoch_specific_accs, key=epoch_specific_accs.get)\n",
    "        best_acc_this_epoch = epoch_specific_accs[best_method_this_epoch]\n",
    "        pp_diff_best = (best_acc_this_epoch - gold_standard_accuracy) * 100\n",
    "\n",
    "        # Find worst method/accuracy for this epoch count\n",
    "        worst_method_this_epoch = min(epoch_specific_accs, key=epoch_specific_accs.get)\n",
    "        worst_acc_this_epoch = epoch_specific_accs[worst_method_this_epoch]\n",
    "        pp_diff_worst = (worst_acc_this_epoch - gold_standard_accuracy) * 100\n",
    "\n",
    "        print(\n",
    "            f\"    Best  Accuracy ({num_epochs}ep): {best_acc_this_epoch:.4f} (using {best_method_this_epoch}) | Diff to Gold: {pp_diff_best:+.2f} pp\"\n",
    "        )\n",
    "        print(\n",
    "            f\"    Worst Accuracy ({num_epochs}ep): {worst_acc_this_epoch:.4f}                            | Diff to Gold: {pp_diff_worst:+.2f} pp\"\n",
    "        )\n",
    "\n",
    "print(\"\\n--- End of Summary ---\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 667852,
     "sourceId": 1176357,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 326719,
     "modelInstanceId": 306271,
     "sourceId": 369892,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
